{
    "Mangroves": {
        "f1-score": 0.8973296730721239,
        "precision": 0.915097220808307,
        "recall": 0.8802389345867607,
        "support": 10212
    },
    "Mangroves > Not Mangroves": {
        "f1-score": 0.24053767244428723,
        "precision": 0.1437024513947591,
        "recall": 0.737527114967462,
        "support": 461
    },
    "Not Mangroves": {
        "f1-score": 0.9176089874418519,
        "precision": 0.9781654253234026,
        "recall": 0.8641133081691311,
        "support": 28877
    },
    "Not Mangroves > Mangroves": {
        "f1-score": 0.2093784078516903,
        "precision": 0.12516297262059975,
        "recall": 0.64,
        "support": 450
    },
    "accuracy": 0.86425,
    "accuracy_conf_interval": [
        0.0028086877856928136,
        0.0033567244268036065,
        0.003990391793087961,
        0.004418545418955768
    ],
    "cls_confidence_intervals": {
        "Mangroves": [
            0.004612287255213678,
            0.005512245744035859,
            0.006552822746736506,
            0.007255915316128835
        ],
        "Mangroves > Not Mangroves": [
            0.011827172107178898,
            0.014134913006140634,
            0.016803238420565143,
            0.018606160997878998
        ],
        "Not Mangroves": [
            0.001500607597804291,
            0.0017934090803026893,
            0.0021319607944414627,
            0.0023607119526433363
        ],
        "Not Mangroves > Mangroves": [
            0.011313241328194874,
            0.013520703050769484,
            0.016073080667496378,
            0.01779766013825779
        ]
    },
    "cohen_kappa": 0.7145519664834383,
    "confusion_matrix": [
        [
            8989,
            429,
            495,
            299
        ],
        [
            51,
            340,
            21,
            49
        ],
        [
            730,
            1529,
            24953,
            1665
        ],
        [
            53,
            68,
            41,
            288
        ]
    ],
    "macro avg": {
        "f1-score": 0.5662136852024883,
        "precision": 0.540532017536767,
        "recall": 0.7804698394308385,
        "support": 40000
    },
    "producer_accuracy": [
        91.5097220808307,
        14.370245139475909,
        97.81654253234025,
        12.516297262059975
    ],
    "user_accuracy": [
        88.02389345867607,
        73.7527114967462,
        86.41133081691311,
        64.0
    ],
    "weighted avg": {
        "f1-score": 0.896660837557524,
        "precision": 0.9428506493432646,
        "recall": 0.86425,
        "support": 40000
    }
}