{
    "Mangroves": {
        "f1-score": 0.897575019377699,
        "precision": 0.9142792691179787,
        "recall": 0.8814702044367116,
        "support": 4598
    },
    "Mangroves > Not Mangroves": {
        "f1-score": 0.2564516129032258,
        "precision": 0.1546692607003891,
        "recall": 0.75,
        "support": 212
    },
    "Not Mangroves": {
        "f1-score": 0.9197306672107733,
        "precision": 0.9783816634832436,
        "recall": 0.8677138677138677,
        "support": 12987
    },
    "Not Mangroves > Mangroves": {
        "f1-score": 0.2091503267973856,
        "precision": 0.12536728697355534,
        "recall": 0.6305418719211823,
        "support": 203
    },
    "accuracy": 0.8671666666666666,
    "accuracy_conf_interval": [
        0.004148703700860169,
        0.004958206862003617,
        0.0058941948920757286,
        0.006526619236719047
    ],
    "cls_confidence_intervals": {
        "Mangroves": [
            0.006895683998134526,
            0.008241183314843702,
            0.009796916899788687,
            0.01084808824096773
        ],
        "Mangroves > Not Mangroves": [
            0.01849535307761739,
            0.02210420245861591,
            0.026276934555395443,
            0.029096348134300534
        ],
        "Not Mangroves": [
            0.0022223916658131743,
            0.002656029064020623,
            0.0031574223056979856,
            0.003496201523047555
        ],
        "Not Mangroves > Mangroves": [
            0.016995578397638905,
            0.0203117888166904,
            0.024146157113718692,
            0.02673694650360267
        ]
    },
    "cohen_kappa": 0.7198185524686374,
    "confusion_matrix": [
        [
            4053,
            178,
            219,
            148
        ],
        [
            21,
            159,
            11,
            21
        ],
        [
            332,
            662,
            11269,
            724
        ],
        [
            27,
            29,
            19,
            128
        ]
    ],
    "macro avg": {
        "f1-score": 0.570726906572271,
        "precision": 0.5431743700687918,
        "recall": 0.7824314860179404,
        "support": 18000
    },
    "producer_accuracy": [
        91.42792691179787,
        15.46692607003891,
        97.83816634832436,
        12.536728697355533
    ],
    "user_accuracy": [
        88.14702044367117,
        75.0,
        86.77138677138677,
        63.05418719211823
    ],
    "weighted avg": {
        "f1-score": 0.8982454095800181,
        "precision": 0.942685454754748,
        "recall": 0.8671666666666666,
        "support": 18000
    }
}