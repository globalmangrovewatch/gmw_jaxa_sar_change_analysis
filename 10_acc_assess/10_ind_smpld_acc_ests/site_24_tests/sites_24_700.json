{
    "Mangroves": {
        "f1-score": 0.8669553531431986,
        "precision": 0.8652757078986587,
        "recall": 0.8686415320167564,
        "support": 3342
    },
    "Mangroves > Not Mangroves": {
        "f1-score": 0.29517502365184484,
        "precision": 0.18682634730538922,
        "recall": 0.7027027027027027,
        "support": 222
    },
    "Not Mangroves": {
        "f1-score": 0.9272851790678,
        "precision": 0.9831710234068,
        "recall": 0.8774109933673858,
        "support": 13117
    },
    "Not Mangroves > Mangroves": {
        "f1-score": 0.16617790811339198,
        "precision": 0.09402654867256637,
        "recall": 0.7142857142857143,
        "support": 119
    },
    "accuracy": 0.872202380952381,
    "accuracy_conf_interval": [
        0.004224343471989684,
        0.005048605612865719,
        0.006001658713253637,
        0.006645613510813039
    ],
    "cls_confidence_intervals": {
        "Mangroves": [
            0.009667135292115249,
            0.011553405593015787,
            0.013734405628432032,
            0.015208054301010576
        ],
        "Mangroves > Not Mangroves": [
            0.02212133441358616,
            0.026437692347944436,
            0.031428481209546194,
            0.034800635845763594
        ],
        "Not Mangroves": [
            0.0019497681711039712,
            0.002330210741075478,
            0.0027700974626050324,
            0.0030673182203952718
        ],
        "Not Mangroves > Mangroves": [
            0.015919983602176575,
            0.019026321866015907,
            0.022618025483580134,
            0.02504485225220461
        ]
    },
    "cohen_kappa": 0.6922048770545808,
    "confusion_matrix": [
        [
            2903,
            136,
            155,
            148
        ],
        [
            11,
            156,
            35,
            20
        ],
        [
            429,
            528,
            11509,
            651
        ],
        [
            12,
            15,
            7,
            85
        ]
    ],
    "macro avg": {
        "f1-score": 0.5638983659940588,
        "precision": 0.5323249068208535,
        "recall": 0.7907602355931399,
        "support": 16800
    },
    "producer_accuracy": [
        86.52757078986588,
        18.682634730538922,
        98.31710234068,
        9.402654867256636
    ],
    "user_accuracy": [
        86.86415320167565,
        70.27027027027027,
        87.74109933673859,
        71.42857142857143
    ],
    "weighted avg": {
        "f1-score": 0.9015397922829229,
        "precision": 0.9428970439415562,
        "recall": 0.872202380952381,
        "support": 16800
    }
}