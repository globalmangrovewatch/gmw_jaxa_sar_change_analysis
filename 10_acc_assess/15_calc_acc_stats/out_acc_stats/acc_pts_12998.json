{
    "Mangroves": {
        "f1-score": 0.8708578507277795,
        "precision": 0.8837209302325582,
        "recall": 0.8583638583638583,
        "support": 3276
    },
    "Mangroves > Not Mangroves": {
        "f1-score": 0.6044117647058824,
        "precision": 0.5150375939849624,
        "recall": 0.7313167259786477,
        "support": 562
    },
    "Not Mangroves": {
        "f1-score": 0.9462622131333789,
        "precision": 0.9606689734717416,
        "recall": 0.9322811730467876,
        "support": 8934
    },
    "Not Mangroves > Mangroves": {
        "f1-score": 0.5261324041811847,
        "precision": 0.4339080459770115,
        "recall": 0.668141592920354,
        "support": 226
    },
    "accuracy": 0.9003692875827051,
    "accuracy_conf_interval": [
        0.004308365463127383,
        0.005149022138859555,
        0.00612103142017488,
        0.006777794448090639
    ],
    "cls_confidence_intervals": {
        "Mangroves": [
            0.009319703703815707,
            0.011138182475291943,
            0.013240798554811343,
            0.014661485095027151
        ],
        "Mangroves > Not Mangroves": [
            0.029014554355188907,
            0.034675930814737965,
            0.041221897346091566,
            0.04564484770511426
        ],
        "Not Mangroves": [
            0.003423645759254889,
            0.004091674200085112,
            0.004864082084795056,
            0.005385979304193668
        ],
        "Not Mangroves > Mangroves": [
            0.043570903816898786,
            0.05207254358604977,
            0.0619025645691306,
            0.0685444706387798
        ]
    },
    "cohen_kappa": 0.7910026498013357,
    "confusion_matrix": [
        [
            2812,
            130,
            254,
            80
        ],
        [
            93,
            411,
            58,
            0
        ],
        [
            233,
            255,
            8329,
            117
        ],
        [
            44,
            2,
            29,
            151
        ]
    ],
    "macro avg": {
        "f1-score": 0.7369160581870563,
        "precision": 0.6983338859165684,
        "recall": 0.7975258375774119,
        "support": 12998
    },
    "producer_accuracy": [
        88.37209302325581,
        51.50375939849624,
        96.06689734717416,
        43.39080459770115
    ],
    "user_accuracy": [
        85.83638583638583,
        73.13167259786478,
        93.22811730467876,
        66.8141592920354
    ],
    "weighted avg": {
        "f1-score": 0.9051717392081448,
        "precision": 0.9128481860785316,
        "recall": 0.9003692875827051,
        "support": 12998
    }
}