{
    "Mangroves": {
        "f1-score": 0.8633461047254151,
        "precision": 0.8805905340859748,
        "recall": 0.8467640918580376,
        "support": 2395
    },
    "Mangroves > Not Mangroves": {
        "f1-score": 0.5802357207615595,
        "precision": 0.48484848484848486,
        "recall": 0.7223476297968398,
        "support": 443
    },
    "Not Mangroves": {
        "f1-score": 0.942528735632184,
        "precision": 0.9589895524715422,
        "recall": 0.9266234744613531,
        "support": 6637
    },
    "Not Mangroves > Mangroves": {
        "f1-score": 0.420253164556962,
        "precision": 0.3360323886639676,
        "recall": 0.5608108108108109,
        "support": 148
    },
    "accuracy": 0.8917177595344488,
    "accuracy_conf_interval": [
        0.0051949447114296235,
        0.006208592460001257,
        0.00738062266928721,
        0.008172534972858799
    ],
    "cls_confidence_intervals": {
        "Mangroves": [
            0.011081620246656586,
            0.013243887611857873,
            0.01574400925287186,
            0.017433280631935364
        ],
        "Mangroves > Not Mangroves": [
            0.03190379840596392,
            0.03812892980224956,
            0.045326737979204834,
            0.05019012188255299
        ],
        "Not Mangroves": [
            0.0040613219683551275,
            0.00485377503535125,
            0.005770048894065517,
            0.006389152852656238
        ],
        "Not Mangroves > Mangroves": [
            0.04929006471630372,
            0.05890763831948494,
            0.07002795779816322,
            0.07754168717564854
        ]
    },
    "cohen_kappa": 0.7731124333844175,
    "confusion_matrix": [
        [
            2028,
            114,
            192,
            61
        ],
        [
            75,
            320,
            48,
            0
        ],
        [
            160,
            224,
            6150,
            103
        ],
        [
            40,
            2,
            23,
            83
        ]
    ],
    "macro avg": {
        "f1-score": 0.7015909314190302,
        "precision": 0.6651152400174923,
        "recall": 0.7641365017317604,
        "support": 9623
    },
    "producer_accuracy": [
        88.05905340859748,
        48.484848484848484,
        95.89895524715422,
        33.603238866396765
    ],
    "user_accuracy": [
        84.67640918580376,
        72.23476297968398,
        92.6623474461353,
        56.08108108108109
    ],
    "weighted avg": {
        "f1-score": 0.8981106756583159,
        "precision": 0.9080690700612783,
        "recall": 0.8917177595344488,
        "support": 9623
    }
}