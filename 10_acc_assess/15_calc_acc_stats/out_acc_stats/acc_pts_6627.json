{
    "Mangroves": {
        "f1-score": 0.8463460337289194,
        "precision": 0.8708226221079691,
        "recall": 0.8232077764277035,
        "support": 1646
    },
    "Mangroves > Not Mangroves": {
        "f1-score": 0.556390977443609,
        "precision": 0.45792079207920794,
        "recall": 0.7088122605363985,
        "support": 261
    },
    "Not Mangroves": {
        "f1-score": 0.9439365568895253,
        "precision": 0.9539180765805877,
        "recall": 0.9341617614998909,
        "support": 4587
    },
    "Not Mangroves > Mangroves": {
        "f1-score": 0.5844155844155843,
        "precision": 0.5142857142857142,
        "recall": 0.6766917293233082,
        "support": 133
    },
    "accuracy": 0.8925607363814697,
    "accuracy_conf_interval": [
        0.006238580213459272,
        0.007455864157548886,
        0.008863348717902503,
        0.009814351799222513
    ],
    "cls_confidence_intervals": {
        "Mangroves": [
            0.013944313411368486,
            0.016665155052611118,
            0.019811128200297914,
            0.02193678573251872
        ],
        "Mangroves > Not Mangroves": [
            0.04065179454727921,
            0.048583852019919056,
            0.05775529347265888,
            0.06395221337315876
        ],
        "Not Mangroves": [
            0.00513032422622846,
            0.006131363099638892,
            0.0072888142970197025,
            0.008070875916871603
        ],
        "Not Mangroves > Mangroves": [
            0.061960867929032035,
            0.07405079337859927,
            0.08802976967966138,
            0.09747502393713577
        ]
    },
    "cohen_kappa": 0.7711994173334569,
    "confusion_matrix": [
        [
            1355,
            103,
            151,
            37
        ],
        [
            45,
            185,
            31,
            0
        ],
        [
            138,
            116,
            4285,
            48
        ],
        [
            18,
            0,
            25,
            90
        ]
    ],
    "macro avg": {
        "f1-score": 0.7327722881194094,
        "precision": 0.6992368012633697,
        "recall": 0.7857183819468253,
        "support": 6627
    },
    "producer_accuracy": [
        87.08226221079691,
        45.79207920792079,
        95.39180765805877,
        51.42857142857142
    ],
    "user_accuracy": [
        82.32077764277035,
        70.88122605363985,
        93.4161761499891,
        67.66917293233082
    ],
    "weighted avg": {
        "f1-score": 0.8972186322333046,
        "precision": 0.9049213188467703,
        "recall": 0.8925607363814697,
        "support": 6627
    }
}