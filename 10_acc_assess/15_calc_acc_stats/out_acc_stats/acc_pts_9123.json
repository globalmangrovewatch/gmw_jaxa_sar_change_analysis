{
    "Mangroves": {
        "f1-score": 0.8531959728400842,
        "precision": 0.8709369024856597,
        "recall": 0.8361633776961909,
        "support": 2179
    },
    "Mangroves > Not Mangroves": {
        "f1-score": 0.5812897366030881,
        "precision": 0.48558421851289835,
        "recall": 0.7239819004524887,
        "support": 442
    },
    "Not Mangroves": {
        "f1-score": 0.9412329863891113,
        "precision": 0.9585779517286367,
        "recall": 0.9245045611827619,
        "support": 6358
    },
    "Not Mangroves > Mangroves": {
        "f1-score": 0.41145833333333337,
        "precision": 0.32916666666666666,
        "recall": 0.5486111111111112,
        "support": 144
    },
    "accuracy": 0.8877562205414885,
    "accuracy_conf_interval": [
        0.005420046513407615,
        0.006477616564804222,
        0.00770043193673155,
        0.00852665853938515
    ],
    "cls_confidence_intervals": {
        "Mangroves": [
            0.012021464994833446,
            0.01436711670114241,
            0.017079276486562153,
            0.01891181688211603
        ],
        "Mangroves > Not Mangroves": [
            0.03192938579802961,
            0.03815950985618174,
            0.04536309079842012,
            0.050230375218851465
        ],
        "Not Mangroves": [
            0.004173229589001434,
            0.004987518289294396,
            0.005929039599008135,
            0.006565202646112012
        ],
        "Not Mangroves > Mangroves": [
            0.049745462058064856,
            0.059451893679150686,
            0.07067495524103118,
            0.07825810494500447
        ]
    },
    "cohen_kappa": 0.762638986297095,
    "confusion_matrix": [
        [
            1822,
            114,
            183,
            60
        ],
        [
            74,
            320,
            48,
            0
        ],
        [
            156,
            223,
            5878,
            101
        ],
        [
            40,
            2,
            23,
            79
        ]
    ],
    "macro avg": {
        "f1-score": 0.6967942572914042,
        "precision": 0.6610664348484654,
        "recall": 0.7583152376106381,
        "support": 9123
    },
    "producer_accuracy": [
        87.09369024856596,
        48.558421851289836,
        95.85779517286367,
        32.916666666666664
    ],
    "user_accuracy": [
        83.6163377696191,
        72.39819004524887,
        92.4504561182762,
        54.861111111111114
    ],
    "weighted avg": {
        "f1-score": 0.8944046274097422,
        "precision": 0.9047942948799326,
        "recall": 0.8877562205414885,
        "support": 9123
    }
}