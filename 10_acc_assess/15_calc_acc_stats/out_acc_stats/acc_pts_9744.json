{
    "Mangroves": {
        "f1-score": 0.8547256466038191,
        "precision": 0.8658178256611165,
        "recall": 0.8439140811455847,
        "support": 2095
    },
    "Mangroves > Not Mangroves": {
        "f1-score": 0.6081582200247219,
        "precision": 0.537117903930131,
        "recall": 0.7008547008547008,
        "support": 351
    },
    "Not Mangroves": {
        "f1-score": 0.9523608472310183,
        "precision": 0.9653352353780313,
        "recall": 0.9397305929731982,
        "support": 7201
    },
    "Not Mangroves > Mangroves": {
        "f1-score": 0.37462235649546827,
        "precision": 0.26495726495726496,
        "recall": 0.6391752577319587,
        "support": 97
    },
    "accuracy": 0.9075328407224958,
    "accuracy_conf_interval": [
        0.004812825804630014,
        0.005751913766509042,
        0.0068377342224316675,
        0.0075713966926496575
    ],
    "cls_confidence_intervals": {
        "Mangroves": [
            0.01237019805913701,
            0.014783895241407647,
            0.01757473260840807,
            0.019460433532057005
        ],
        "Mangroves > Not Mangroves": [
            0.0382103587359001,
            0.04566603848924646,
            0.054286668204053194,
            0.06011141801135504
        ],
        "Not Mangroves": [
            0.0035831752210061544,
            0.004282331361690282,
            0.005090730649356306,
            0.00563694638426578
        ],
        "Not Mangroves > Mangroves": [
            0.047312961181470534,
            0.056544758485172104,
            0.06721902411757705,
            0.0744313657610939
        ]
    },
    "cohen_kappa": 0.7805442708775986,
    "confusion_matrix": [
        [
            1768,
            66,
            188,
            73
        ],
        [
            62,
            246,
            43,
            0
        ],
        [
            189,
            146,
            6767,
            99
        ],
        [
            23,
            0,
            12,
            62
        ]
    ],
    "macro avg": {
        "f1-score": 0.6974667675887569,
        "precision": 0.658307057481636,
        "recall": 0.7809186581763606,
        "support": 9744
    },
    "producer_accuracy": [
        86.58178256611166,
        53.7117903930131,
        96.53352353780313,
        26.495726495726498
    ],
    "user_accuracy": [
        84.39140811455847,
        70.08547008547008,
        93.97305929731982,
        63.91752577319587
    ],
    "weighted avg": {
        "f1-score": 0.9132186570560654,
        "precision": 0.9215411138852191,
        "recall": 0.9075328407224958,
        "support": 9744
    }
}