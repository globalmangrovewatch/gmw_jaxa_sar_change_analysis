{
    "Mangroves": {
        "f1-score": 0.8528301886792454,
        "precision": 0.8609523809523809,
        "recall": 0.8448598130841122,
        "support": 1605
    },
    "Mangroves > Not Mangroves": {
        "f1-score": 0.643076923076923,
        "precision": 0.5726027397260274,
        "recall": 0.7333333333333333,
        "support": 285
    },
    "Not Mangroves": {
        "f1-score": 0.9534300555257029,
        "precision": 0.966237066618261,
        "recall": 0.9409581050026515,
        "support": 5657
    },
    "Not Mangroves > Mangroves": {
        "f1-score": 0.3361344537815126,
        "precision": 0.23809523809523808,
        "recall": 0.5714285714285714,
        "support": 70
    },
    "accuracy": 0.9095444400682684,
    "accuracy_conf_interval": [
        0.005389909400068841,
        0.006441599039106664,
        0.007657615184244147,
        0.008479247714742446
    ],
    "cls_confidence_intervals": {
        "Mangroves": [
            0.014297987499870369,
            0.01708783871935727,
            0.020313604191889,
            0.022493175457113143
        ],
        "Mangroves > Not Mangroves": [
            0.04246586683923619,
            0.05075188963713594,
            0.060332603497207524,
            0.0668060588080667
        ],
        "Not Mangroves": [
            0.003990886665133587,
            0.004769596258330384,
            0.0056699792254641815,
            0.00627834609514918
        ],
        "Not Mangroves > Mangroves": [
            0.053890834158164806,
            0.06440611887195306,
            0.07656441682227073,
            0.08477948300491782
        ]
    },
    "cohen_kappa": 0.7832309182054682,
    "confusion_matrix": [
        [
            1356,
            44,
            149,
            56
        ],
        [
            52,
            209,
            24,
            0
        ],
        [
            150,
            112,
            5323,
            72
        ],
        [
            17,
            0,
            13,
            40
        ]
    ],
    "macro avg": {
        "f1-score": 0.696367905265846,
        "precision": 0.6594718563479769,
        "recall": 0.7726449557121671,
        "support": 7617
    },
    "producer_accuracy": [
        86.09523809523809,
        57.26027397260274,
        96.6237066618261,
        23.809523809523807
    ],
    "user_accuracy": [
        84.48598130841121,
        73.33333333333333,
        94.09581050026516,
        57.14285714285714
    ],
    "weighted avg": {
        "f1-score": 0.9149471723487882,
        "precision": 0.922632283678175,
        "recall": 0.9095444400682684,
        "support": 7617
    }
}