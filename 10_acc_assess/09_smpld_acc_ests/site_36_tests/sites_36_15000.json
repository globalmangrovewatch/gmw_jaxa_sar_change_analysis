{
    "Mangroves": {
        "f1-score": 0.8793012175754367,
        "precision": 0.8927707605482397,
        "recall": 0.866232073011734,
        "support": 3835
    },
    "Mangroves > Not Mangroves": {
        "f1-score": 0.22413793103448276,
        "precision": 0.13648293963254593,
        "recall": 0.6265060240963856,
        "support": 166
    },
    "Not Mangroves": {
        "f1-score": 0.9198691342350702,
        "precision": 0.9792078178604845,
        "recall": 0.8673112338858195,
        "support": 10860
    },
    "Not Mangroves > Mangroves": {
        "f1-score": 0.16972034715525552,
        "precision": 0.09799554565701558,
        "recall": 0.6330935251798561,
        "support": 139
    },
    "accuracy": 0.8622,
    "accuracy_conf_interval": [
        0.004615585885063781,
        0.005516188008978665,
        0.0065575092147552505,
        0.007261104624063754
    ],
    "cls_confidence_intervals": {
        "Mangroves": [
            0.008318415415527991,
            0.009941520862460283,
            0.011818236535475745,
            0.013086287665891597
        ],
        "Mangroves > Not Mangroves": [
            0.020395812343971656,
            0.02437548304523442,
            0.02897697729356949,
            0.032086095028931026
        ],
        "Not Mangroves": [
            0.002385977573134667,
            0.0028515341727706994,
            0.0033898339910998624,
            0.003753550084565513
        ],
        "Not Mangroves > Mangroves": [
            0.016270960417262784,
            0.01944578196209455,
            0.023116669373306274,
            0.02559699870520609
        ]
    },
    "cohen_kappa": 0.7075450022025385,
    "confusion_matrix": [
        [
            3322,
            179,
            170,
            164
        ],
        [
            31,
            104,
            20,
            11
        ],
        [
            346,
            460,
            9419,
            635
        ],
        [
            22,
            19,
            10,
            88
        ]
    ],
    "macro avg": {
        "f1-score": 0.5482571575000612,
        "precision": 0.5266142659245714,
        "recall": 0.7482857140434488,
        "support": 15000
    },
    "producer_accuracy": [
        89.27707605482397,
        13.648293963254593,
        97.92078178604845,
        9.799554565701559
    ],
    "user_accuracy": [
        86.6232073011734,
        62.65060240963856,
        86.73112338858195,
        63.30935251798561
    ],
    "weighted avg": {
        "f1-score": 0.8948464661333978,
        "precision": 0.939616687832846,
        "recall": 0.8622,
        "support": 15000
    }
}