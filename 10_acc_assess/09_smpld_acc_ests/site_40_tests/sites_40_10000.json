{
    "Mangroves": {
        "f1-score": 0.8817878028404343,
        "precision": 0.8910932883073026,
        "recall": 0.8726746589499793,
        "support": 2419
    },
    "Mangroves > Not Mangroves": {
        "f1-score": 0.25103448275862067,
        "precision": 0.157439446366782,
        "recall": 0.6190476190476191,
        "support": 147
    },
    "Not Mangroves": {
        "f1-score": 0.9213029691553762,
        "precision": 0.9784172661870504,
        "recall": 0.8704889009941441,
        "support": 7343
    },
    "Not Mangroves > Mangroves": {
        "f1-score": 0.19312602291325695,
        "precision": 0.11346153846153846,
        "recall": 0.6483516483516484,
        "support": 91
    },
    "accuracy": 0.8653,
    "accuracy_conf_interval": [
        0.005599006836359463,
        0.00669149597516131,
        0.007954686541900945,
        0.008808193681589888
    ],
    "cls_confidence_intervals": {
        "Mangroves": [
            0.010496638163219187,
            0.012544762682871712,
            0.014912906658719943,
            0.016513003939698477
        ],
        "Mangroves > Not Mangroves": [
            0.024844900807904812,
            0.029692686331398436,
            0.035297938342937936,
            0.03908527078316733
        ],
        "Not Mangroves": [
            0.002948511325242199,
            0.0035238306082162867,
            0.004189043529155076,
            0.004638511718978582
        ],
        "Not Mangroves > Mangroves": [
            0.02280947561803995,
            0.027260105006925793,
            0.03240614523782505,
            0.03588319944789212
        ]
    },
    "cohen_kappa": 0.7082223083475453,
    "confusion_matrix": [
        [
            2111,
            103,
            113,
            92
        ],
        [
            25,
            91,
            20,
            11
        ],
        [
            226,
            367,
            6392,
            358
        ],
        [
            7,
            17,
            8,
            59
        ]
    ],
    "macro avg": {
        "f1-score": 0.5618128194169221,
        "precision": 0.5351028848306684,
        "recall": 0.7526407068358477,
        "support": 10000
    },
    "producer_accuracy": [
        89.10932883073026,
        15.7439446366782,
        97.84172661870504,
        11.346153846153847
    ],
    "user_accuracy": [
        87.26746589499793,
        61.904761904761905,
        87.04889009941441,
        64.83516483516483
    ],
    "weighted avg": {
        "f1-score": 0.8952648934629562,
        "precision": 0.9373541248642794,
        "recall": 0.8653,
        "support": 10000
    }
}