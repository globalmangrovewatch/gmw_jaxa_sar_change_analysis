{
    "Mangroves": {
        "f1-score": 0.8781722319859402,
        "precision": 0.9018192318798729,
        "recall": 0.8557336621454994,
        "support": 7299
    },
    "Mangroves > Not Mangroves": {
        "f1-score": 0.2518628912071535,
        "precision": 0.15211521152115212,
        "recall": 0.7316017316017316,
        "support": 231
    },
    "Not Mangroves": {
        "f1-score": 0.9240910057410164,
        "precision": 0.9727569226833792,
        "recall": 0.8800624855357556,
        "support": 17284
    },
    "Not Mangroves > Mangroves": {
        "f1-score": 0.1521164021164021,
        "precision": 0.08672699849170437,
        "recall": 0.6182795698924731,
        "support": 186
    },
    "accuracy": 0.86964,
    "accuracy_conf_interval": [
        0.0034923340096150025,
        0.004173765035881345,
        0.0049616696600018025,
        0.005494037649272383
    ],
    "cls_confidence_intervals": {
        "Mangroves": [
            0.005863751587439017,
            0.0070078982386466305,
            0.008330817804105434,
            0.00922468237536138
        ],
        "Mangroves > Not Mangroves": [
            0.01767020399738559,
            0.02111804867980229,
            0.025104619093846602,
            0.02779824775198465
        ],
        "Not Mangroves": [
            0.002134997528019322,
            0.0025515824115352873,
            0.0030332586831006226,
            0.0033587156233474704
        ],
        "Not Mangroves > Mangroves": [
            0.012675046278796774,
            0.015148226040513219,
            0.018007840139997858,
            0.019940011828838828
        ]
    },
    "cohen_kappa": 0.7317023655974485,
    "confusion_matrix": [
        [
            6246,
            424,
            392,
            237
        ],
        [
            13,
            169,
            10,
            39
        ],
        [
            654,
            484,
            15211,
            935
        ],
        [
            13,
            34,
            24,
            115
        ]
    ],
    "macro avg": {
        "f1-score": 0.5515606327626281,
        "precision": 0.5283545911440272,
        "recall": 0.7714193622938649,
        "support": 25000
    },
    "producer_accuracy": [
        90.1819231879873,
        15.211521152115212,
        97.27569226833792,
        8.672699849170437
    ],
    "user_accuracy": [
        85.57336621454994,
        73.16017316017316,
        88.00624855357556,
        61.82795698924731
    ],
    "weighted avg": {
        "f1-score": 0.8987296817262244,
        "precision": 0.9378711624292625,
        "recall": 0.86964,
        "support": 25000
    }
}