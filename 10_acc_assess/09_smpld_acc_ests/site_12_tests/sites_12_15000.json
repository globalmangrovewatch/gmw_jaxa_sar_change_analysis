{
    "Mangroves": {
        "f1-score": 0.8911284599006387,
        "precision": 0.9101188750362423,
        "recall": 0.8729143492769744,
        "support": 3596
    },
    "Mangroves > Not Mangroves": {
        "f1-score": 0.17021276595744678,
        "precision": 0.09631728045325778,
        "recall": 0.7311827956989247,
        "support": 93
    },
    "Not Mangroves": {
        "f1-score": 0.9281150159744409,
        "precision": 0.978502080443828,
        "recall": 0.8826630920464701,
        "support": 11190
    },
    "Not Mangroves > Mangroves": {
        "f1-score": 0.20412844036697245,
        "precision": 0.118508655126498,
        "recall": 0.7355371900826446,
        "support": 121
    },
    "accuracy": 0.8782,
    "accuracy_conf_interval": [
        0.0043794399831941985,
        0.005233964857963799,
        0.0062220092444161485,
        0.006889606802829898
    ],
    "cls_confidence_intervals": {
        "Mangroves": [
            0.007986942562800659,
            0.009545370379932494,
            0.01134730254349118,
            0.012564824275625426
        ],
        "Mangroves > Not Mangroves": [
            0.01820964973582714,
            0.02176275212330561,
            0.025871026758827586,
            0.028646887999045138
        ],
        "Not Mangroves": [
            0.002367507106332123,
            0.0028294597124457078,
            0.0033635924132645405,
            0.0037244928867907787
        ],
        "Not Mangroves > Mangroves": [
            0.01934229223491214,
            0.023116398036846217,
            0.027480207870332493,
            0.03042872802809349
        ]
    },
    "cohen_kappa": 0.7245424311049763,
    "confusion_matrix": [
        [
            3139,
            170,
            198,
            89
        ],
        [
            9,
            68,
            8,
            8
        ],
        [
            291,
            457,
            9877,
            565
        ],
        [
            10,
            11,
            11,
            89
        ]
    ],
    "macro avg": {
        "f1-score": 0.5483961705498747,
        "precision": 0.5258617227649565,
        "recall": 0.8055743567762534,
        "support": 15000
    },
    "producer_accuracy": [
        91.01188750362424,
        9.631728045325778,
        97.8502080443828,
        11.8508655126498
    ],
    "user_accuracy": [
        87.29143492769744,
        73.11827956989248,
        88.26630920464702,
        73.55371900826447
    ],
    "weighted avg": {
        "f1-score": 0.9087089532716758,
        "precision": 0.9497015206099482,
        "recall": 0.8782,
        "support": 15000
    }
}