{
    "Mangroves": {
        "f1-score": 0.8941463786919026,
        "precision": 0.9061098221191028,
        "recall": 0.8824947273275083,
        "support": 6638
    },
    "Mangroves > Not Mangroves": {
        "f1-score": 0.14972067039106143,
        "precision": 0.08427672955974842,
        "recall": 0.67,
        "support": 200
    },
    "Not Mangroves": {
        "f1-score": 0.9187207534797771,
        "precision": 0.9834726564992662,
        "recall": 0.8619686800894855,
        "support": 17880
    },
    "Not Mangroves > Mangroves": {
        "f1-score": 0.22879177377892032,
        "precision": 0.13971742543171115,
        "recall": 0.6312056737588653,
        "support": 282
    },
    "accuracy": 0.86328,
    "accuracy_conf_interval": [
        0.0035634092936251923,
        0.004258708667991084,
        0.005062648569601646,
        0.005605851205824999
    ],
    "cls_confidence_intervals": {
        "Mangroves": [
            0.005949220741901671,
            0.0071100443012971195,
            0.008452246541848106,
            0.009359139947625801
        ],
        "Mangroves > Not Mangroves": [
            0.01142565873388069,
            0.013655055560003753,
            0.016232795640208544,
            0.017974511910617184
        ],
        "Not Mangroves": [
            0.0016702372467425168,
            0.0019961371973264224,
            0.0023729590151890636,
            0.00262756835158274
        ],
        "Not Mangroves > Mangroves": [
            0.015929604169876373,
            0.01903781961765713,
            0.02263169372915363,
            0.025059987047732348
        ]
    },
    "cohen_kappa": 0.7163114275978524,
    "confusion_matrix": [
        [
            5858,
            349,
            204,
            227
        ],
        [
            10,
            134,
            26,
            30
        ],
        [
            570,
            1059,
            15412,
            839
        ],
        [
            27,
            48,
            29,
            178
        ]
    ],
    "macro avg": {
        "f1-score": 0.5478448940854154,
        "precision": 0.5283941584024572,
        "recall": 0.7614172702939648,
        "support": 25000
    },
    "producer_accuracy": [
        90.61098221191028,
        8.427672955974842,
        98.34726564992661,
        13.971742543171114
    ],
    "user_accuracy": [
        88.24947273275083,
        67.0,
        86.19686800894854,
        63.12056737588653
    ],
    "weighted avg": {
        "f1-score": 0.8982613659303653,
        "precision": 0.946220150292687,
        "recall": 0.86328,
        "support": 25000
    }
}