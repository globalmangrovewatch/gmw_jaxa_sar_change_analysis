{
    "Mangroves": {
        "f1-score": {
            "90th": [
                0.8660401835541985,
                0.8786641882678571
            ],
            "95th": [
                0.8644862180419954,
                0.8797435964304839
            ],
            "99th": [
                0.8619429066386234,
                0.8822210716963089
            ],
            "mean": 0.872429325775067,
            "median": 0.8725662508241696
        },
        "precision": {
            "90th": [
                0.882738161024799,
                0.8990902982392897
            ],
            "95th": [
                0.8813733963235788,
                0.9008130633616118
            ],
            "99th": [
                0.8788512645775853,
                0.9028258956056711
            ],
            "mean": 0.8911664661629366,
            "median": 0.89123227612111
        },
        "producer_accuracy": {
            "90th": [
                88.2738161024799,
                89.90902982392896
            ],
            "95th": [
                88.13733963235788,
                90.08130633616119
            ],
            "99th": [
                87.88512645775853,
                90.28258956056712
            ],
            "mean": 89.11664661629366,
            "median": 89.123227612111
        },
        "recall": {
            "90th": [
                0.8447643993878102,
                0.8639662415830611
            ],
            "95th": [
                0.8428620376796443,
                0.8658741988073543
            ],
            "99th": [
                0.839596366758974,
                0.8686185977902872
            ],
            "mean": 0.8544943947328232,
            "median": 0.8547128871692056
        },
        "support": {
            "90th": [
                3776.95,
                3959.05
            ],
            "95th": [
                3761.0,
                3974.025
            ],
            "99th": [
                3745.99,
                4019.0299999999997
            ],
            "mean": 3871.546,
            "median": 3873.0
        },
        "user_accuracy": {
            "90th": [
                84.47643993878103,
                86.39662415830612
            ],
            "95th": [
                84.28620376796444,
                86.58741988073542
            ],
            "99th": [
                83.9596366758974,
                86.86185977902872
            ],
            "mean": 85.44943947328231,
            "median": 85.47128871692055
        }
    },
    "Mangroves > Not Mangroves": {
        "f1-score": {
            "90th": [
                0.573146532936696,
                0.6223968932634106
            ],
            "95th": [
                0.5685755475867416,
                0.6274842713951435
            ],
            "99th": [
                0.5625372565096692,
                0.6379448715870405
            ],
            "mean": 0.5981798745729251,
            "median": 0.5978895516572817
        },
        "precision": {
            "90th": [
                0.4781416477092752,
                0.5331049890591977
            ],
            "95th": [
                0.47280129248711705,
                0.5371820860873688
            ],
            "99th": [
                0.4641186146041691,
                0.5516148387096774
            ],
            "mean": 0.5058908846380304,
            "median": 0.5056434558842264
        },
        "producer_accuracy": {
            "90th": [
                47.81416477092752,
                53.310498905919765
            ],
            "95th": [
                47.2801292487117,
                53.71820860873688
            ],
            "99th": [
                46.41186146041691,
                55.16148387096774
            ],
            "mean": 50.58908846380305,
            "median": 50.56434558842264
        },
        "recall": {
            "90th": [
                0.7027950622240065,
                0.7629999139932915
            ],
            "95th": [
                0.6953440189328743,
                0.7692307692307693
            ],
            "99th": [
                0.6875990670186097,
                0.7770642913202133
            ],
            "mean": 0.7321326632522515,
            "median": 0.7316679667186687
        },
        "support": {
            "90th": [
                566.0,
                647.0
            ],
            "95th": [
                559.0,
                653.0
            ],
            "99th": [
                541.0,
                673.0
            ],
            "mean": 606.611,
            "median": 607.0
        },
        "user_accuracy": {
            "90th": [
                70.27950622240064,
                76.29999139932914
            ],
            "95th": [
                69.53440189328744,
                76.92307692307693
            ],
            "99th": [
                68.75990670186098,
                77.70642913202133
            ],
            "mean": 73.21326632522515,
            "median": 73.16679667186688
        }
    },
    "Not Mangroves": {
        "f1-score": {
            "90th": [
                0.9429055429093792,
                0.9480994412070101
            ],
            "95th": [
                0.9423526237526318,
                0.9485064679026842
            ],
            "99th": [
                0.9414558825238544,
                0.9494260194115262
            ],
            "mean": 0.9455254593089735,
            "median": 0.94554664569962
        },
        "precision": {
            "90th": [
                0.9539101225434332,
                0.9606764199880135
            ],
            "95th": [
                0.9532386104467453,
                0.9611541688592198
            ],
            "99th": [
                0.9519616544566631,
                0.962470224593448
            ],
            "mean": 0.9572854784422905,
            "median": 0.9572645022318591
        },
        "producer_accuracy": {
            "90th": [
                95.39101225434332,
                96.06764199880134
            ],
            "95th": [
                95.32386104467454,
                96.11541688592197
            ],
            "99th": [
                95.19616544566631,
                96.24702245934479
            ],
            "mean": 95.72854784422904,
            "median": 95.7264502231859
        },
        "recall": {
            "90th": [
                0.9300939351382973,
                0.9379990404002664
            ],
            "95th": [
                0.9291836720031276,
                0.9385227829829353
            ],
            "99th": [
                0.9279868479918408,
                0.9401588607166663
            ],
            "mean": 0.934056083878264,
            "median": 0.934128803383896
        },
        "support": {
            "90th": [
                10071.0,
                10265.05
            ],
            "95th": [
                10059.95,
                10281.075
            ],
            "99th": [
                10023.98,
                10312.045
            ],
            "mean": 10164.871,
            "median": 10163.0
        },
        "user_accuracy": {
            "90th": [
                93.00939351382972,
                93.79990404002663
            ],
            "95th": [
                92.91836720031276,
                93.85227829829353
            ],
            "99th": [
                92.79868479918409,
                94.01588607166664
            ],
            "mean": 93.4056083878264,
            "median": 93.41288033838961
        }
    },
    "Not Mangroves > Mangroves": {
        "f1-score": {
            "90th": [
                0.546287754544212,
                0.6160719341530497
            ],
            "95th": [
                0.5396440872560275,
                0.6235477724658767
            ],
            "99th": [
                0.5297978875010478,
                0.6370885595320994
            ],
            "mean": 0.5818071518052411,
            "median": 0.5816912573610302
        },
        "precision": {
            "90th": [
                0.46444950582414807,
                0.5437120202558636
            ],
            "95th": [
                0.45599240506329114,
                0.5512825281646885
            ],
            "99th": [
                0.4390211874846021,
                0.5676828282828282
            ],
            "mean": 0.5023562330829175,
            "median": 0.5019610557401255
        },
        "producer_accuracy": {
            "90th": [
                46.444950582414805,
                54.371202025586356
            ],
            "95th": [
                45.59924050632912,
                55.12825281646885
            ],
            "99th": [
                43.90211874846022,
                56.76828282828283
            ],
            "mean": 50.235623308291764,
            "median": 50.19610557401255
        },
        "recall": {
            "90th": [
                0.6508659916188557,
                0.7313852583586626
            ],
            "95th": [
                0.6432390852390852,
                0.7392584874533298
            ],
            "99th": [
                0.6256740477938179,
                0.7542920634920636
            ],
            "mean": 0.6919828992428382,
            "median": 0.6927153526504941
        },
        "support": {
            "90th": [
                326.0,
                388.04999999999995
            ],
            "95th": [
                321.975,
                396.025
            ],
            "99th": [
                304.0,
                406.02
            ],
            "mean": 356.972,
            "median": 357.0
        },
        "user_accuracy": {
            "90th": [
                65.08659916188559,
                73.13852583586626
            ],
            "95th": [
                64.32390852390853,
                73.92584874533298
            ],
            "99th": [
                62.56740477938178,
                75.42920634920635
            ],
            "mean": 69.19828992428383,
            "median": 69.27153526504942
        }
    },
    "accuracy": {
        "90th": [
            0.8954633333333333,
            0.9034666666666666
        ],
        "95th": [
            0.8947983333333334,
            0.9044666666666666
        ],
        "99th": [
            0.893,
            0.905735
        ],
        "mean": 0.8995913333333333,
        "median": 0.8996333333333333
    },
    "cohen_kappa": {
        "90th": [
            0.784535777899075,
            0.8003323377706288
        ],
        "95th": [
            0.7831235018850462,
            0.8018479132603391
        ],
        "99th": [
            0.7807877852781363,
            0.8052527890879755
        ],
        "mean": 0.7929187698141793,
        "median": 0.7930831177658466
    },
    "macro avg": {
        "f1-score": {
            "90th": [
                0.7372616499113576,
                0.7606072921414735
            ],
            "95th": [
                0.7347908038148726,
                0.7628351556066479
            ],
            "99th": [
                0.7309711955268825,
                0.769098065511863
            ],
            "mean": 0.7494854528655517,
            "median": 0.7496202301354433
        },
        "precision": {
            "90th": [
                0.7017303219582941,
                0.7266243275460454
            ],
            "95th": [
                0.6994953738198243,
                0.7291009299171658
            ],
            "99th": [
                0.6947406133096873,
                0.7352428229084079
            ],
            "mean": 0.7141747655815438,
            "median": 0.7140238854862115
        },
        "recall": {
            "90th": [
                0.7896904105763725,
                0.8164930463105269
            ],
            "95th": [
                0.786498156665704,
                0.8187357125778142
            ],
            "99th": [
                0.7837585031665526,
                0.8229902234773204
            ],
            "mean": 0.8031665102765442,
            "median": 0.803223068291315
        }
    },
    "weighted avg": {
        "f1-score": {
            "90th": [
                0.9000185997029401,
                0.9075945914684348
            ],
            "95th": [
                0.8993438865720048,
                0.9086962784063686
            ],
            "99th": [
                0.8981352585211126,
                0.909965870781942
            ],
            "mean": 0.9039832808094281,
            "median": 0.9039896985737739
        },
        "precision": {
            "90th": [
                0.9072668220366495,
                0.9149652968395594
            ],
            "95th": [
                0.9065317815435707,
                0.9158358201478654
            ],
            "99th": [
                0.9055397141600349,
                0.9170184457509514
            ],
            "mean": 0.9111827561301461,
            "median": 0.9111538649566634
        },
        "recall": {
            "90th": [
                0.8954633333333333,
                0.9034666666666666
            ],
            "95th": [
                0.8947983333333334,
                0.9044666666666666
            ],
            "99th": [
                0.893,
                0.905735
            ],
            "mean": 0.8995913333333333,
            "median": 0.8996333333333333
        }
    }
}