{
    "Mangroves": {
        "f1-score": {
            "90th": [
                0.8670363985998439,
                0.8800549564440051
            ],
            "95th": [
                0.8656506681095731,
                0.8810303464746901
            ],
            "99th": [
                0.862208168641449,
                0.8830869339432206
            ],
            "mean": 0.8735070204701941,
            "median": 0.8735159388262448
        },
        "precision": {
            "90th": [
                0.8801898778665033,
                0.8967907460833416
            ],
            "95th": [
                0.8792414715191409,
                0.8981191741027175
            ],
            "99th": [
                0.8755636449068527,
                0.9011278830277223
            ],
            "mean": 0.888267752243183,
            "median": 0.8882171980362648
        },
        "producer_accuracy": {
            "90th": [
                88.01898778665031,
                89.67907460833416
            ],
            "95th": [
                87.9241471519141,
                89.81191741027175
            ],
            "99th": [
                87.55636449068527,
                90.11278830277223
            ],
            "mean": 88.8267752243183,
            "median": 88.82171980362648
        },
        "recall": {
            "90th": [
                0.8496971152431388,
                0.8681525176228622
            ],
            "95th": [
                0.8479762161106493,
                0.8695217782926186
            ],
            "99th": [
                0.8450997927197135,
                0.8717361887724229
            ],
            "mean": 0.8592572431819792,
            "median": 0.8592095133454418
        },
        "support": {
            "90th": [
                3779.0,
                3963.05
            ],
            "95th": [
                3765.0,
                3981.0
            ],
            "99th": [
                3734.995,
                4016.0299999999997
            ],
            "mean": 3868.956,
            "median": 3868.0
        },
        "user_accuracy": {
            "90th": [
                84.96971152431388,
                86.81525176228621
            ],
            "95th": [
                84.79762161106493,
                86.95217782926184
            ],
            "99th": [
                84.50997927197133,
                87.17361887724229
            ],
            "mean": 85.9257243181979,
            "median": 85.92095133454418
        }
    },
    "Mangroves > Not Mangroves": {
        "f1-score": {
            "90th": [
                0.5789473684210527,
                0.6268130698250529
            ],
            "95th": [
                0.5747644804846734,
                0.6320356530262191
            ],
            "99th": [
                0.5657348861205214,
                0.6389469264987938
            ],
            "mean": 0.6038846270850474,
            "median": 0.6041379310344828
        },
        "precision": {
            "90th": [
                0.4898191372357326,
                0.5447783732660783
            ],
            "95th": [
                0.48527505383988123,
                0.5507134433962264
            ],
            "99th": [
                0.4742978957870647,
                0.5602349463402095
            ],
            "mean": 0.5178639308116614,
            "median": 0.5182478831922128
        },
        "producer_accuracy": {
            "90th": [
                48.981913723573264,
                54.47783732660782
            ],
            "95th": [
                48.52750538398813,
                55.071344339622634
            ],
            "99th": [
                47.42978957870647,
                56.02349463402095
            ],
            "mean": 51.78639308116614,
            "median": 51.824788319221284
        },
        "recall": {
            "90th": [
                0.6946599205460906,
                0.7532082704876822
            ],
            "95th": [
                0.6898951814678062,
                0.7585672684130343
            ],
            "99th": [
                0.6812384793645739,
                0.7691157351662549
            ],
            "mean": 0.7246447907011937,
            "median": 0.7248596044056241
        },
        "support": {
            "90th": [
                566.0,
                644.0
            ],
            "95th": [
                560.975,
                651.025
            ],
            "99th": [
                542.985,
                669.01
            ],
            "mean": 605.187,
            "median": 605.0
        },
        "user_accuracy": {
            "90th": [
                69.46599205460906,
                75.32082704876822
            ],
            "95th": [
                68.98951814678063,
                75.85672684130344
            ],
            "99th": [
                68.1238479364574,
                76.91157351662548
            ],
            "mean": 72.46447907011935,
            "median": 72.48596044056242
        }
    },
    "Not Mangroves": {
        "f1-score": {
            "90th": [
                0.9437536500486037,
                0.9489829518212248
            ],
            "95th": [
                0.9432503975846814,
                0.9495833045072852
            ],
            "99th": [
                0.9422732693447338,
                0.950576112111926
            ],
            "mean": 0.9464232607142967,
            "median": 0.9463824288081715
        },
        "precision": {
            "90th": [
                0.9540091455236319,
                0.9608691964103934
            ],
            "95th": [
                0.9534903503912577,
                0.9614885061085606
            ],
            "99th": [
                0.9521155442181555,
                0.9625288364787431
            ],
            "mean": 0.9574043031409155,
            "median": 0.9573869181770547
        },
        "producer_accuracy": {
            "90th": [
                95.40091455236319,
                96.08691964103934
            ],
            "95th": [
                95.34903503912578,
                96.14885061085606
            ],
            "99th": [
                95.21155442181555,
                96.25288364787431
            ],
            "mean": 95.74043031409155,
            "median": 95.73869181770547
        },
        "recall": {
            "90th": [
                0.9317588150247317,
                0.9395689003159172
            ],
            "95th": [
                0.9310131118014321,
                0.9402828910682979
            ],
            "99th": [
                0.9294384099118164,
                0.9412867725407571
            ],
            "mean": 0.9356961991840712,
            "median": 0.9356745129029367
        },
        "support": {
            "90th": [
                10067.95,
                10267.0
            ],
            "95th": [
                10049.0,
                10279.025
            ],
            "99th": [
                9995.0,
                10308.005
            ],
            "mean": 10168.068,
            "median": 10169.0
        },
        "user_accuracy": {
            "90th": [
                93.17588150247316,
                93.95689003159171
            ],
            "95th": [
                93.1013111801432,
                94.02828910682977
            ],
            "99th": [
                92.94384099118164,
                94.12867725407571
            ],
            "mean": 93.56961991840713,
            "median": 93.56745129029366
        }
    },
    "Not Mangroves > Mangroves": {
        "f1-score": {
            "90th": [
                0.5607701564380264,
                0.6272748316498317
            ],
            "95th": [
                0.5539149928263988,
                0.6341535319834329
            ],
            "99th": [
                0.5452036277985935,
                0.6472185267159044
            ],
            "mean": 0.5954804981397431,
            "median": 0.5956452677041809
        },
        "precision": {
            "90th": [
                0.48640005747466464,
                0.5599212846487316
            ],
            "95th": [
                0.4805000969180074,
                0.5673554050441137
            ],
            "99th": [
                0.46520251716247135,
                0.5844543885241915
            ],
            "mean": 0.5232031556092004,
            "median": 0.5239107836933924
        },
        "producer_accuracy": {
            "90th": [
                48.64000574746647,
                55.99212846487316
            ],
            "95th": [
                48.05000969180074,
                56.735540504411375
            ],
            "99th": [
                46.52025171624714,
                58.44543885241916
            ],
            "mean": 52.32031556092004,
            "median": 52.39107836933924
        },
        "recall": {
            "90th": [
                0.65109527569205,
                0.7340736233647703
            ],
            "95th": [
                0.6430474884706469,
                0.7415730337078652
            ],
            "99th": [
                0.6341721976401179,
                0.7583239557637407
            ],
            "mean": 0.6917097380112968,
            "median": 0.6914600550964187
        },
        "support": {
            "90th": [
                327.0,
                389.0
            ],
            "95th": [
                319.975,
                396.0
            ],
            "99th": [
                313.0,
                406.0
            ],
            "mean": 357.789,
            "median": 358.0
        },
        "user_accuracy": {
            "90th": [
                65.109527569205,
                73.40736233647704
            ],
            "95th": [
                64.30474884706469,
                74.15730337078652
            ],
            "99th": [
                63.41721976401179,
                75.83239557637407
            ],
            "mean": 69.17097380112968,
            "median": 69.14600550964187
        }
    },
    "accuracy": {
        "90th": [
            0.8978666666666667,
            0.9056666666666666
        ],
        "95th": [
            0.8969333333333334,
            0.9060683333333334
        ],
        "99th": [
            0.8953323333333333,
            0.907069
        ],
        "mean": 0.9016462666666666,
        "median": 0.9016
    },
    "cohen_kappa": {
        "90th": [
            0.7889307357510468,
            0.8042863270948601
        ],
        "95th": [
            0.7873509046666975,
            0.8058849003382508
        ],
        "99th": [
            0.784546854597826,
            0.8075963189435623
        ],
        "mean": 0.796577254818821,
        "median": 0.7965338704879326
    },
    "macro avg": {
        "f1-score": {
            "90th": [
                0.7433060723374068,
                0.7653572543377737
            ],
            "95th": [
                0.7412798945277137,
                0.7672655172358152
            ],
            "99th": [
                0.7370395090230331,
                0.7712614503554481
            ],
            "mean": 0.7548238516023204,
            "median": 0.75511494235008
        },
        "precision": {
            "90th": [
                0.709982049008234,
                0.7331663311446417
            ],
            "95th": [
                0.7075928070719744,
                0.7346060321483125
            ],
            "99th": [
                0.7026641392621243,
                0.7399216866900765
            ],
            "mean": 0.72168478545124,
            "median": 0.7217788433419707
        },
        "recall": {
            "90th": [
                0.7904594906023632,
                0.8158379287644256
            ],
            "95th": [
                0.7881450270105834,
                0.819001795097345
            ],
            "99th": [
                0.7842361941253422,
                0.8240628789054475
            ],
            "mean": 0.8028269927696351,
            "median": 0.8027291627795952
        }
    },
    "weighted avg": {
        "f1-score": {
            "90th": [
                0.9019482432596408,
                0.90935695147128
            ],
            "95th": [
                0.9009428793499858,
                0.9097673162106363
            ],
            "99th": [
                0.8997889056329712,
                0.910966756727298
            ],
            "mean": 0.9054508113296663,
            "median": 0.9054233957945677
        },
        "precision": {
            "90th": [
                0.9078610927382534,
                0.9153944046551872
            ],
            "95th": [
                0.9071795571752298,
                0.9160294451826365
            ],
            "99th": [
                0.9058683650277441,
                0.9169092384485474
            ],
            "mean": 0.911522096044702,
            "median": 0.911491504558547
        },
        "recall": {
            "90th": [
                0.8978666666666667,
                0.9056666666666666
            ],
            "95th": [
                0.8969333333333334,
                0.9060683333333334
            ],
            "99th": [
                0.8953323333333333,
                0.907069
            ],
            "mean": 0.9016462666666666,
            "median": 0.9016
        }
    }
}